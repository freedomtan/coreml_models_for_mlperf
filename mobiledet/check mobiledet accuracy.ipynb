{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eac4e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:TensorFlow version 2.9.2 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.8.0 is the most recent version that has been tested.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import PIL.Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import coremltools as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99a36f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "Height = 320  \n",
    "Width = 320\n",
    "\n",
    "def load_image(path, resize_to=None):\n",
    "    # resize_to: (Width, Height)\n",
    "    img = PIL.Image.open(path)\n",
    "    if resize_to is not None:\n",
    "        img = img.resize(resize_to, PIL.Image.ANTIALIAS)\n",
    "    img_np = np.array(img).astype(np.float32)\n",
    "    return img_np, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "763059f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_np, img = load_image('test_images/image2.jpg', resize_to=(Width, Height))\n",
    "\n",
    "model = ct.models.MLModel('MobileDet_4_outputs.mlmodel')\n",
    "out_dict = model.predict({'image': np.expand_dims((img_np/127.5 - 1.0), 0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd6c6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with 2 outputs model verified with Xcode model preview\n",
    "\n",
    "model_2 = ct.models.MLModel('MobileDet.mlmodel')\n",
    "out_dict_2 = model_2.predict({'image': img})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85bafe49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.35302734, 0.38208008, 0.01686096, 0.02557373],\n",
       "         [0.4338379 , 0.39282227, 0.01980591, 0.0231781 ],\n",
       "         [0.06713867, 0.5942383 , 0.02168274, 0.0713501 ],\n",
       "         [0.21789551, 0.28466797, 0.02227783, 0.05194092],\n",
       "         [0.39697266, 0.5805664 , 0.01860046, 0.02972412],\n",
       "         [0.46655273, 0.12683105, 0.06091309, 0.08190918],\n",
       "         [0.02911377, 0.5961914 , 0.01695251, 0.05224609],\n",
       "         [0.17797852, 0.8574219 , 0.0453186 , 0.17919922],\n",
       "         [0.10083008, 0.76171875, 0.03689575, 0.15405273],\n",
       "         [0.5620117 , 0.42919922, 0.01029205, 0.01647949]]], dtype=float32),\n",
       " array([[0.35302734, 0.38208008, 0.01686096, 0.02563477],\n",
       "        [0.4338379 , 0.39282227, 0.01980591, 0.0231781 ],\n",
       "        [0.06713867, 0.5942383 , 0.02168274, 0.0713501 ],\n",
       "        [0.21789551, 0.28466797, 0.02224731, 0.05194092],\n",
       "        [0.39697266, 0.5805664 , 0.01856995, 0.02978516],\n",
       "        [0.46655273, 0.12683105, 0.06088257, 0.08190918],\n",
       "        [0.02911377, 0.5961914 , 0.01695251, 0.05227661],\n",
       "        [0.17797852, 0.8574219 , 0.0453186 , 0.17919922],\n",
       "        [0.10076904, 0.76171875, 0.03689575, 0.1538086 ],\n",
       "        [0.5620117 , 0.42919922, 0.01031494, 0.01647949],\n",
       "        [0.26098633, 0.546875  , 0.00952911, 0.02230835],\n",
       "        [0.13305664, 0.61621094, 0.01445007, 0.02987671],\n",
       "        [0.23461914, 0.43115234, 0.01531982, 0.03427124],\n",
       "        [0.4699707 , 0.53759766, 0.85058594, 0.1743164 ],\n",
       "        [0.80566406, 0.45239258, 0.01831055, 0.03057861],\n",
       "        [0.35083008, 0.43017578, 0.01464844, 0.02209473],\n",
       "        [0.49267578, 0.52685547, 0.9472656 , 0.20935059],\n",
       "        [0.1583252 , 0.48950195, 0.00800323, 0.01766968],\n",
       "        [0.18017578, 0.48168945, 0.00870514, 0.02084351],\n",
       "        [0.09759521, 0.48413086, 0.01263428, 0.02633667],\n",
       "        [0.48388672, 0.5410156 , 0.00963593, 0.01257324],\n",
       "        [0.13598633, 0.6044922 , 0.00945282, 0.02468872],\n",
       "        [0.57714844, 0.43017578, 0.00840759, 0.01502228],\n",
       "        [0.61376953, 0.63183594, 0.01319122, 0.01532745],\n",
       "        [0.28100586, 0.5473633 , 0.00701904, 0.01391602],\n",
       "        [0.2932129 , 0.4946289 , 0.00827789, 0.0160675 ],\n",
       "        [0.03671265, 0.60498047, 0.01580811, 0.04473877],\n",
       "        [0.6147461 , 0.63916016, 0.01905823, 0.01376343],\n",
       "        [0.44873047, 0.4255371 , 0.01098633, 0.01672363],\n",
       "        [0.8100586 , 0.46313477, 0.0145874 , 0.02970886],\n",
       "        [0.58935547, 0.5488281 , 0.01085663, 0.01144409]], dtype=float32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if bounding boxes match\n",
    "out_dict['coordinates'], out_dict_2['coordinates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bd9d821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 10, 4), dtype=float32, numpy=\n",
       " array([[[0.36930528, 0.3446542 , 0.3948696 , 0.36154133],\n",
       "         [0.38126433, 0.42392153, 0.40443414, 0.44371176],\n",
       "         [0.55859756, 0.05629784, 0.62990713, 0.07799782],\n",
       "         [0.258843  , 0.20680143, 0.3107981 , 0.22903194],\n",
       "         [0.56560236, 0.38757455, 0.59533376, 0.40617454],\n",
       "         [0.08592385, 0.4358106 , 0.16783425, 0.49678382],\n",
       "         [0.5697846 , 0.02065526, 0.6220425 , 0.03757773],\n",
       "         [0.26443386, 0.2014876 , 0.30679524, 0.22032481],\n",
       "         [0.7677408 , 0.15532103, 0.9469773 , 0.20065379],\n",
       "         [0.6850095 , 0.08234983, 0.8390647 , 0.11924426]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 10), dtype=float32, numpy=array([[38., 38.,  1., 38.,  1., 38.,  1., 38.,  1.,  1.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       " array([[0.74776036, 0.7410878 , 0.71043926, 0.7037864 , 0.69625336,\n",
       "         0.6919317 , 0.68733567, 0.6803323 , 0.6753018 , 0.621736  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([10.], dtype=float32)>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference with TF saved\n",
    "\n",
    "original_model = tf.saved_model.load('mobiledet')\n",
    "input_nodes = ['image_tensor:0']\n",
    "output_nodes = ['detection_boxes:0', 'detection_classes:0', 'detection_scores:0', 'num_detections:0']\n",
    "\n",
    "p = original_model.prune(input_nodes, output_nodes)\n",
    "\n",
    "img_tensor = tf.expand_dims(tf.convert_to_tensor(np.asarray(img), dtype=tf.uint8), 0)\n",
    "p(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb8e5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=int64, numpy=array([[38, 38,  1, 38,  1, 38,  1,  1,  1, 38]])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get the classes of boxes \n",
    "\n",
    "tf.math.argmax(out_dict['confidence'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "497ae430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.369293212890625, 0.34459686279296875, 0.394866943359375, 0.36145782470703125]\n",
      "[0.38123321533203125, 0.4239349365234375, 0.40441131591796875, 0.4437408447265625]\n",
      "[0.558563232421875, 0.05629730224609375, 0.629913330078125, 0.07798004150390625]\n",
      "[0.258697509765625, 0.206756591796875, 0.310638427734375, 0.229034423828125]\n",
      "[0.565704345703125, 0.38767242431640625, 0.595428466796875, 0.40627288818359375]\n",
      "[0.08587646484375, 0.43609619140625, 0.16778564453125, 0.49700927734375]\n",
      "[0.570068359375, 0.02063751220703125, 0.622314453125, 0.03759002685546875]\n",
      "[0.767822265625, 0.1553192138671875, 0.947021484375, 0.2006378173828125]\n",
      "[0.6846923828125, 0.0823822021484375, 0.8387451171875, 0.1192779541015625]\n",
      "[0.42095947265625, 0.5568656921386719, 0.43743896484375, 0.5671577453613281]\n"
     ]
    }
   ],
   "source": [
    "# to get bounding boxes\n",
    "# TensorFlow/TF Lite (y1, x1, y2, x2)\n",
    "# Core ML (x, y, x_len, y_len)\n",
    "\n",
    "for box in out_dict['coordinates'][0]:\n",
    "    x1 = box[0] - box [2] / 2\n",
    "    y1 = box[1] - box [3] / 2\n",
    "    x2 = box[0] + box [2] / 2\n",
    "    y2 = box[1] + box [3] / 2\n",
    "    print([y1, x1, y2, x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ef685f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
